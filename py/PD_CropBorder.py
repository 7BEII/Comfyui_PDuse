import os
import cv2
import numpy as np
import torch
from PIL import Image, ImageOps
import glob

class PD_CropBorderBatch:
    """
    æ‰¹é‡è£åˆ‡å›¾ç‰‡è¾¹æ¡†èŠ‚ç‚¹
    è¯»å–æŒ‡å®šè·¯å¾„ä¸‹çš„æ‰€æœ‰å›¾ç‰‡ï¼Œè‡ªåŠ¨æ£€æµ‹å¹¶å»é™¤ä¸è¾¹ç¼˜è¿æ¥çš„é»‘è‰²æˆ–ç™½è‰²è¾¹æ¡†ï¼Œç„¶åä¿å­˜
    """
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "input_path": ("STRING", {
                    "default": "",
                    "multiline": False,
                    "placeholder": "è¾“å…¥å›¾ç‰‡æ–‡ä»¶å¤¹è·¯å¾„"
                }),
                "border_color": (["black", "white"], {
                    "default": "black",
                    "tooltip": "é€‰æ‹©è¦åˆ é™¤çš„è¾¹æ¡†é¢œè‰²"
                }),
                "threshold": ("INT", {
                    "default": 10,
                    "min": 0,
                    "max": 255,
                    "step": 1,
                    "tooltip": "é¢œè‰²æ£€æµ‹é˜ˆå€¼ï¼Œ0-255ï¼Œå€¼è¶Šå°æ£€æµ‹è¶Šä¸¥æ ¼"
                }),
                "padding": ("INT", {
                    "default": 0,
                    "min": 0,
                    "max": 100,
                    "step": 1,
                    "tooltip": "è£åˆ‡åé¢å¤–ä¿ç•™çš„è¾¹è·åƒç´ "
                }),
            },
            "optional": {
                "output_path": ("STRING", {
                    "default": "",
                    "multiline": False,
                    "placeholder": "è¾“å‡ºè·¯å¾„ï¼ˆå¯é€‰ï¼Œä¸å¡«åˆ™è¦†ç›–åŸå›¾ï¼‰"
                }),
            }
        }
    
    RETURN_TYPES = ("STRING",)
    RETURN_NAMES = ("å¤„ç†ç»“æœ",)
    FUNCTION = "batch_crop_border"
    CATEGORY = "PDuse/å›¾åƒå¤„ç†"
    OUTPUT_NODE = True
    
    def detect_border(self, image_array, border_color="black", threshold=10):
        """
        æ£€æµ‹å›¾åƒè¾¹ç¼˜è¿æ¥çš„è¾¹æ¡†åŒºåŸŸ - ç®€åŒ–ç‰ˆæœ¬
        """
        # è½¬æ¢ä¸ºç°åº¦å›¾
        if len(image_array.shape) == 3:
            gray = cv2.cvtColor(image_array, cv2.COLOR_RGB2GRAY)
        else:
            gray = image_array.copy()
        
        height, width = gray.shape
        
        # æ ¹æ®è¾¹æ¡†é¢œè‰²è®¾ç½®æ£€æµ‹æ¡ä»¶
        if border_color == "black":
            # æ£€æµ‹é»‘è‰²ï¼šåƒç´ å€¼å°äºç­‰äºé˜ˆå€¼
            is_border = gray <= threshold
        else:  # white
            # æ£€æµ‹ç™½è‰²ï¼šåƒç´ å€¼å¤§äºç­‰äº255-é˜ˆå€¼
            is_border = gray >= (255 - threshold)
        
        # ä»å››ä¸ªè¾¹ç¼˜å‘å†…æ‰«æï¼Œæ‰¾åˆ°ç¬¬ä¸€ä¸ªéè¾¹æ¡†åƒç´ 
        # ä¸Šè¾¹ç¼˜
        top = 0
        for y in range(height):
            if not np.all(is_border[y, :]):
                top = y
                break
        else:
            # æ•´ä¸ªå›¾åƒéƒ½æ˜¯è¾¹æ¡†
            return None
        
        # ä¸‹è¾¹ç¼˜
        bottom = height - 1
        for y in range(height - 1, -1, -1):
            if not np.all(is_border[y, :]):
                bottom = y + 1
                break
        
        # å·¦è¾¹ç¼˜
        left = 0
        for x in range(width):
            if not np.all(is_border[:, x]):
                left = x
                break
        
        # å³è¾¹ç¼˜
        right = width - 1
        for x in range(width - 1, -1, -1):
            if not np.all(is_border[:, x]):
                right = x + 1
                break
        
        # éªŒè¯è¾¹ç•Œæ¡†æœ‰æ•ˆæ€§
        if left >= right or top >= bottom:
            return None
        
        return (left, top, right, bottom)
    
    def crop_image_border(self, image_path, border_color="black", threshold=10, padding=0):
        """
        è£åˆ‡å•å¼ å›¾ç‰‡çš„è¾¹æ¡†
        """
        try:
            # è¯»å–å›¾åƒ
            image = Image.open(image_path)
            image_array = np.array(image)
            
            # æ£€æµ‹è¾¹æ¡†
            bbox = self.detect_border(image_array, border_color, threshold)
            
            if bbox is None:
                print(f"è­¦å‘Š: {os.path.basename(image_path)} æ•´ä¸ªå›¾åƒéƒ½æ˜¯è¾¹æ¡†ï¼Œè·³è¿‡å¤„ç†")
                return False
            
            x_min, y_min, x_max, y_max = bbox
            
            # æ·»åŠ padding
            height, width = image_array.shape[:2]
            x_min = max(0, x_min - padding)
            y_min = max(0, y_min - padding)
            x_max = min(width, x_max + padding)
            y_max = min(height, y_max + padding)
            
            # è£åˆ‡å›¾åƒ
            cropped_image = image.crop((x_min, y_min, x_max, y_max))
            
            return cropped_image
            
        except Exception as e:
            print(f"å¤„ç†å›¾ç‰‡ {image_path} æ—¶å‡ºé”™: {str(e)}")
            return False
    
    def get_image_files(self, path):
        """
        è·å–è·¯å¾„ä¸‹çš„æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶
        """
        supported_formats = ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.tiff', '*.tif', '*.webp']
        image_files = []
        
        for format in supported_formats:
            image_files.extend(glob.glob(os.path.join(path, format)))
            image_files.extend(glob.glob(os.path.join(path, format.upper())))
        
        return image_files
    
    def batch_crop_border(self, input_path, border_color="black", threshold=10, padding=0, output_path=""):
        """
        æ‰¹é‡å¤„ç†å›¾ç‰‡
        """
        # éªŒè¯è¾“å…¥è·¯å¾„
        if not input_path or not os.path.exists(input_path):
            return (f"é”™è¯¯: è¾“å…¥è·¯å¾„ä¸å­˜åœ¨: {input_path}",)
        
        if not os.path.isdir(input_path):
            return (f"é”™è¯¯: è¾“å…¥è·¯å¾„ä¸æ˜¯æ–‡ä»¶å¤¹: {input_path}",)
        
        # è®¾ç½®è¾“å‡ºè·¯å¾„
        if output_path and output_path.strip():
            output_dir = output_path.strip()
            # åˆ›å»ºè¾“å‡ºç›®å½•
            if not os.path.exists(output_dir):
                try:
                    os.makedirs(output_dir)
                except Exception as e:
                    return (f"é”™è¯¯: æ— æ³•åˆ›å»ºè¾“å‡ºç›®å½• {output_dir}: {str(e)}",)
        else:
            # è¦†ç›–åŸå›¾
            output_dir = input_path
        
        # è·å–æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶
        image_files = self.get_image_files(input_path)
        
        if not image_files:
            return (f"è­¦å‘Š: åœ¨è·¯å¾„ {input_path} ä¸­æ²¡æœ‰æ‰¾åˆ°ä»»ä½•å›¾ç‰‡æ–‡ä»¶",)
        
        # æ‰¹é‡å¤„ç†
        processed_count = 0
        failed_files = []
        
        color_name = "é»‘è‰²" if border_color == "black" else "ç™½è‰²"
        print(f"å¼€å§‹æ‰¹é‡å¤„ç†{color_name}è¾¹æ¡†ï¼Œå…± {len(image_files)} ä¸ªæ–‡ä»¶...")
        
        for image_file in image_files:
            try:
                # è£åˆ‡å›¾ç‰‡
                cropped_image = self.crop_image_border(image_file, border_color, threshold, padding)
                
                if cropped_image:
                    # ç¡®å®šè¾“å‡ºæ–‡ä»¶è·¯å¾„
                    filename = os.path.basename(image_file)
                    output_file = os.path.join(output_dir, filename)
                    
                    # ä¿å­˜è£åˆ‡åçš„å›¾ç‰‡
                    cropped_image.save(output_file, quality=95)
                    processed_count += 1
                    print(f"æˆåŠŸå¤„ç†: {filename}")
                else:
                    failed_files.append(os.path.basename(image_file))
                    
            except Exception as e:
                failed_files.append(f"{os.path.basename(image_file)} (é”™è¯¯: {str(e)})")
                print(f"å¤„ç† {image_file} å¤±è´¥: {str(e)}")
        
        # ç”Ÿæˆç»“æœæŠ¥å‘Š
        result_message = f"ğŸ¨ {color_name}è¾¹æ¡†æ‰¹é‡è£åˆ‡å®Œæˆï¼\n\n"
        result_message += f"ğŸ“Š å¤„ç†ç»Ÿè®¡:\n"
        result_message += f"â€¢ æ€»æ–‡ä»¶æ•°: {len(image_files)}\n"
        result_message += f"â€¢ æˆåŠŸå¤„ç†: {processed_count}\n"
        result_message += f"â€¢ å¤„ç†å¤±è´¥: {len(failed_files)}\n\n"
        result_message += f"ğŸ“ è·¯å¾„ä¿¡æ¯:\n"
        result_message += f"â€¢ è¾“å…¥è·¯å¾„: {input_path}\n"
        result_message += f"â€¢ è¾“å‡ºè·¯å¾„: {output_dir}\n\n"
        result_message += f"âš™ï¸ å¤„ç†å‚æ•°:\n"
        result_message += f"â€¢ è¾¹æ¡†é¢œè‰²: {color_name}\n"
        result_message += f"â€¢ æ£€æµ‹é˜ˆå€¼: {threshold}\n"
        result_message += f"â€¢ è¾¹è·åƒç´ : {padding}\n"
        
        if failed_files:
            result_message += f"\nâŒ å¤±è´¥æ–‡ä»¶:\n"
            for failed_file in failed_files[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ªå¤±è´¥æ–‡ä»¶
                result_message += f"â€¢ {failed_file}\n"
            if len(failed_files) > 10:
                result_message += f"â€¢ ... è¿˜æœ‰ {len(failed_files) - 10} ä¸ªæ–‡ä»¶å¤±è´¥\n"
        
        if processed_count > 0:
            result_message += f"\nâœ… æ‰¹é‡å¤„ç†ä»»åŠ¡å®Œæˆï¼"
        else:
            result_message += f"\nâš ï¸ æ²¡æœ‰æ–‡ä»¶è¢«æˆåŠŸå¤„ç†ã€‚"
        
        return (result_message,)


class PD_CropBorder:
    """
    å•å¼ å›¾ç‰‡è£åˆ‡è¾¹æ¡†èŠ‚ç‚¹
    è¾“å…¥å•å¼ å›¾ç‰‡ï¼Œè‡ªåŠ¨æ£€æµ‹å¹¶å»é™¤ä¸è¾¹ç¼˜è¿æ¥çš„é»‘è‰²æˆ–ç™½è‰²è¾¹æ¡†ï¼Œè¾“å‡ºè£åˆ‡åçš„å›¾ç‰‡
    """
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image": ("IMAGE",),
                "border_color": (["black", "white"], {
                    "default": "black",
                    "tooltip": "é€‰æ‹©è¦åˆ é™¤çš„è¾¹æ¡†é¢œè‰²"
                }),
                "threshold": ("INT", {
                    "default": 10,
                    "min": 0,
                    "max": 255,
                    "step": 1,
                    "tooltip": "é¢œè‰²æ£€æµ‹é˜ˆå€¼ï¼Œ0-255ï¼Œå€¼è¶Šå°æ£€æµ‹è¶Šä¸¥æ ¼"
                }),
                "padding": ("INT", {
                    "default": 0,
                    "min": 0,
                    "max": 100,
                    "step": 1,
                    "tooltip": "è£åˆ‡åé¢å¤–ä¿ç•™çš„è¾¹è·åƒç´ "
                }),
            }
        }
    
    RETURN_TYPES = ("IMAGE",)
    RETURN_NAMES = ("crop image",)
    FUNCTION = "crop_border"
    CATEGORY = "PDuse/å›¾åƒå¤„ç†"
    
    def detect_border(self, image_array, border_color="black", threshold=10):
        """
        æ£€æµ‹å›¾åƒè¾¹ç¼˜è¿æ¥çš„è¾¹æ¡†åŒºåŸŸ - ç®€åŒ–ç‰ˆæœ¬
        """
        # è½¬æ¢ä¸ºç°åº¦å›¾
        if len(image_array.shape) == 3:
            gray = cv2.cvtColor(image_array, cv2.COLOR_RGB2GRAY)
        else:
            gray = image_array.copy()
        
        height, width = gray.shape
        
        # æ ¹æ®è¾¹æ¡†é¢œè‰²è®¾ç½®æ£€æµ‹æ¡ä»¶
        if border_color == "black":
            # æ£€æµ‹é»‘è‰²ï¼šåƒç´ å€¼å°äºç­‰äºé˜ˆå€¼
            is_border = gray <= threshold
        else:  # white
            # æ£€æµ‹ç™½è‰²ï¼šåƒç´ å€¼å¤§äºç­‰äº255-é˜ˆå€¼
            is_border = gray >= (255 - threshold)
        
        # ä»å››ä¸ªè¾¹ç¼˜å‘å†…æ‰«æï¼Œæ‰¾åˆ°ç¬¬ä¸€ä¸ªéè¾¹æ¡†åƒç´ 
        # ä¸Šè¾¹ç¼˜
        top = 0
        for y in range(height):
            if not np.all(is_border[y, :]):
                top = y
                break
        else:
            # æ•´ä¸ªå›¾åƒéƒ½æ˜¯è¾¹æ¡†
            return None
        
        # ä¸‹è¾¹ç¼˜
        bottom = height - 1
        for y in range(height - 1, -1, -1):
            if not np.all(is_border[y, :]):
                bottom = y + 1
                break
        
        # å·¦è¾¹ç¼˜
        left = 0
        for x in range(width):
            if not np.all(is_border[:, x]):
                left = x
                break
        
        # å³è¾¹ç¼˜
        right = width - 1
        for x in range(width - 1, -1, -1):
            if not np.all(is_border[:, x]):
                right = x + 1
                break
        
        # éªŒè¯è¾¹ç•Œæ¡†æœ‰æ•ˆæ€§
        if left >= right or top >= bottom:
            return None
        
        return (left, top, right, bottom)
    
    def crop_border(self, image, border_color="black", threshold=10, padding=0):
        """
        è£åˆ‡å•å¼ å›¾ç‰‡çš„è¾¹æ¡†
        """
        # ç¡®ä¿è¾“å…¥å¼ é‡æ ¼å¼ä¸º (B, H, W, C)
        if len(image.shape) != 4:
            raise ValueError(f"è¾“å…¥å›¾åƒå¼ é‡æ ¼å¼é”™è¯¯ï¼ŒæœŸæœ› (B, H, W, C)ï¼Œå®é™… {image.shape}")
        
        batch_size = image.shape[0]
        cropped_images = []
        
        for i in range(batch_size):
            # è·å–å•å¼ å›¾ç‰‡ (H, W, C)
            single_image = image[i]
            
            # è½¬æ¢ä¸ºnumpyæ•°ç»„ (0-255)
            if single_image.dtype == torch.float32:
                # å‡è®¾è¾“å…¥æ˜¯0-1èŒƒå›´çš„float32
                image_array = (single_image.cpu().numpy() * 255).astype(np.uint8)
            else:
                image_array = single_image.cpu().numpy()
            
            # æ£€æµ‹è¾¹æ¡†
            bbox = self.detect_border(image_array, border_color, threshold)
            
            if bbox is None:
                print(f"è­¦å‘Š: ç¬¬{i+1}å¼ å›¾ç‰‡æ•´ä¸ªéƒ½æ˜¯è¾¹æ¡†ï¼Œè¿”å›åŸå›¾")
                cropped_images.append(single_image)
                continue
            
            left, top, right, bottom = bbox
            
            # æ·»åŠ padding
            height, width = image_array.shape[:2]
            left = max(0, left - padding)
            top = max(0, top - padding)
            right = min(width, right + padding)
            bottom = min(height, bottom + padding)
            
            # è£åˆ‡å›¾åƒ
            cropped_array = image_array[top:bottom, left:right, :]
            
            # è½¬æ¢å›å¼ é‡æ ¼å¼
            if single_image.dtype == torch.float32:
                # è½¬æ¢å›0-1èŒƒå›´
                cropped_tensor = torch.from_numpy(cropped_array.astype(np.float32) / 255.0)
            else:
                cropped_tensor = torch.from_numpy(cropped_array)
            
            cropped_images.append(cropped_tensor)
            
            color_name = "é»‘è‰²" if border_color == "black" else "ç™½è‰²"
            print(f"æˆåŠŸè£åˆ‡ç¬¬{i+1}å¼ å›¾ç‰‡çš„{color_name}è¾¹æ¡†: {left},{top},{right},{bottom}")
        
        # å°†æ‰€æœ‰è£åˆ‡åçš„å›¾ç‰‡ç»„åˆæˆæ‰¹æ¬¡
        # ç”±äºè£åˆ‡åå°ºå¯¸å¯èƒ½ä¸åŒï¼Œéœ€è¦æ‰¾åˆ°æœ€å¤§å°ºå¯¸å¹¶padding
        if len(cropped_images) == 1:
            result = cropped_images[0].unsqueeze(0)
        else:
            # å¤šå›¾æƒ…å†µä¸‹ï¼Œéœ€è¦ç»Ÿä¸€å°ºå¯¸
            max_h = max(img.shape[0] for img in cropped_images)
            max_w = max(img.shape[1] for img in cropped_images)
            
            padded_images = []
            for img in cropped_images:
                h, w, c = img.shape
                if h < max_h or w < max_w:
                    # åˆ›å»ºç©ºç™½å›¾åƒå¹¶å¤åˆ¶
                    padded = torch.zeros(max_h, max_w, c, dtype=img.dtype)
                    padded[:h, :w, :] = img
                    padded_images.append(padded)
                else:
                    padded_images.append(img)
            
            result = torch.stack(padded_images)
        
        return (result,)


NODE_CLASS_MAPPINGS = {
    "PD_BatchCropBlackBorder": PD_CropBorderBatch,
    "PD_CropBorder": PD_CropBorder,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "PD_BatchCropBlackBorder": "PD_BatchCropBlackBorder",
    "PD_CropBorder": "PD_CropBorder",
} 