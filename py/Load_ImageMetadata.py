import os
import json
import torch
import numpy as np
from PIL import Image, ImageOps, ImageSequence
import folder_paths
import node_helpers


class PD_LoadImageMetadata:
    """
    åŠ è½½å›¾ç‰‡å¹¶æå–å…ƒæ•°æ®ä¿¡æ¯
    æ”¯æŒè¯»å–å›¾ç‰‡ä¸­çš„workflowã€promptã€LoRAç­‰å‚æ•°ä¿¡æ¯
    """
    
    @classmethod
    def INPUT_TYPES(s):
        input_dir = folder_paths.get_input_directory()
        files = [f for f in os.listdir(input_dir) if os.path.isfile(os.path.join(input_dir, f))]
        files = folder_paths.filter_files_content_types(files, ["image"])
        return {
            "required": {
                "image": (sorted(files), {"image_upload": True})
            },
        }

    CATEGORY = "PD:load image"
    
    RETURN_TYPES = ("IMAGE", "MASK", "STRING", "STRING", "STRING")
    RETURN_NAMES = ("å›¾ç‰‡", "é®ç½©", "æç¤ºè¯", "æ¨¡å‹ä¿¡æ¯", "LoRAä¿¡æ¯")
    FUNCTION = "load_image_with_metadata"
    
    def extract_metadata(self, image_path):
        """
        æå–å›¾ç‰‡çš„å…ƒæ•°æ®ä¿¡æ¯
        
        Args:
            image_path: å›¾ç‰‡è·¯å¾„
            
        Returns:
            tuple: (prompt_text, model_info, lora_info)
        """
        try:
            img = Image.open(image_path)
            
            # åˆå§‹åŒ–è¿”å›å€¼
            prompt_text = ""
            model_info = ""
            lora_info = ""
            
            # å°è¯•ä»PNG infoä¸­æå–ä¿¡æ¯
            if hasattr(img, 'info') and img.info:
                info = img.info
                
                # è°ƒè¯•ï¼šæ‰“å°æ‰€æœ‰å¯ç”¨çš„infoé”®
                print(f"ğŸ“ PNG Info é”®: {list(info.keys())}")
                
                # ä¼˜å…ˆä»promptå­—æ®µæå– (ComfyUIæ ¼å¼)
                if 'prompt' in info:
                    try:
                        prompt_data = json.loads(info['prompt'])
                        
                        # æå–å„ç±»ä¿¡æ¯
                        lora_list = []
                        model_list = []
                        prompt_texts = []
                        
                        for node_id, node_data in prompt_data.items():
                            if isinstance(node_data, dict):
                                class_type = node_data.get('class_type', '')
                                inputs = node_data.get('inputs', {})
                                
                                # æå–æ¨¡å‹ä¿¡æ¯
                                if 'CheckpointLoader' in class_type or 'Checkpoint' in class_type:
                                    ckpt_name = inputs.get('ckpt_name', '')
                                    if ckpt_name:
                                        model_list.append(f"[Checkpoint] {ckpt_name}")
                                
                                # æå–LoRAä¿¡æ¯
                                if 'lora' in class_type.lower() or 'LoraLoader' in class_type:
                                    lora_name = inputs.get('lora_name', '')
                                    strength_model = inputs.get('strength_model', 1.0)
                                    strength_clip = inputs.get('strength_clip', 1.0)
                                    
                                    if lora_name:
                                        lora_list.append(
                                            f"lora name: {lora_name}\n"
                                            f"strength_model: {strength_model}\n"
                                            f"strength_clip: {strength_clip}"
                                        )
                                
                                # æå–VAEä¿¡æ¯
                                if 'VAELoader' in class_type:
                                    vae_name = inputs.get('vae_name', '')
                                    if vae_name:
                                        model_list.append(f"[VAE] {vae_name}")
                                
                                # æå–æ–‡æœ¬æç¤ºè¯
                                if class_type in ['CLIPTextEncode', 'CLIPTextEncodeSDXL']:
                                    text = inputs.get('text', '')
                                    if text:
                                        prompt_texts.append(text)
                                
                                # Fluxç³»åˆ—æç¤ºè¯èŠ‚ç‚¹
                                if 'FluxGuidance' in class_type or 'DualCLIPLoader' in class_type:
                                    text = inputs.get('text', '') or inputs.get('guidance', '')
                                    if text:
                                        prompt_texts.append(str(text))
                        
                        # æ ¼å¼åŒ–è¾“å‡º
                        if prompt_texts:
                            prompt_text = "\n\n".join(prompt_texts)
                            print(f"   âœ“ æå–åˆ° {len(prompt_texts)} ä¸ªæç¤ºè¯")
                        
                        if model_list:
                            model_info = "\n".join(model_list)
                            print(f"   âœ“ æå–åˆ° {len(model_list)} ä¸ªæ¨¡å‹")
                        
                        if lora_list:
                            lora_info = "\n\n".join(lora_list)
                            print(f"   âœ“ æå–åˆ° {len(lora_list)} ä¸ªLoRA")
                    
                    except json.JSONDecodeError as e:
                        print(f"âš ï¸  è§£æprompt JSONå¤±è´¥: {e}")
                
                # å¦‚æœpromptå­—æ®µæ²¡æœ‰ä¿¡æ¯ï¼Œå°è¯•ä»workflowå­—æ®µæå–
                if not prompt_text and not model_info and 'workflow' in info:
                    try:
                        workflow_data = json.loads(info['workflow'])
                        
                        # é‡æ–°åˆå§‹åŒ–åˆ—è¡¨
                        lora_list = []
                        model_list = []
                        prompt_texts = []
                        
                        # workflowæ ¼å¼é€šå¸¸æ˜¯ {"nodes": [...], "links": [...]}
                        if 'nodes' in workflow_data:
                            for node in workflow_data['nodes']:
                                if isinstance(node, dict):
                                    node_type = node.get('type', '')
                                    widgets_values = node.get('widgets_values', [])
                                    
                                    # æå–æ¨¡å‹ä¿¡æ¯
                                    if 'CheckpointLoader' in node_type and widgets_values:
                                        model_list.append(f"[Checkpoint] {widgets_values[0]}")
                                    
                                    # æå–LoRAä¿¡æ¯
                                    if 'LoraLoader' in node_type and len(widgets_values) >= 3:
                                        lora_name = widgets_values[0]
                                        strength_model = widgets_values[1]
                                        strength_clip = widgets_values[2]
                                        lora_list.append(
                                            f"lora name: {lora_name}\n"
                                            f"strength_model: {strength_model}\n"
                                            f"strength_clip: {strength_clip}"
                                        )
                                    
                                    # æå–æç¤ºè¯
                                    if 'CLIPTextEncode' in node_type and widgets_values:
                                        prompt_texts.append(str(widgets_values[0]))
                        
                        if prompt_texts:
                            prompt_text = "\n\n".join(prompt_texts)
                            print(f"   âœ“ ä»workflowæå–åˆ° {len(prompt_texts)} ä¸ªæç¤ºè¯")
                        if model_list:
                            model_info = "\n".join(model_list)
                            print(f"   âœ“ ä»workflowæå–åˆ° {len(model_list)} ä¸ªæ¨¡å‹")
                        if lora_list:
                            lora_info = "\n\n".join(lora_list)
                            print(f"   âœ“ ä»workflowæå–åˆ° {len(lora_list)} ä¸ªLoRA")
                    
                    except json.JSONDecodeError as e:
                        print(f"âš ï¸  è§£æworkflow JSONå¤±è´¥: {e}")
                
                # å¦‚æœComfyUIæ ¼å¼æ²¡æœ‰æ‰¾åˆ°ï¼Œå°è¯•Stable Diffusion WebUIæ ¼å¼
                if not prompt_text and 'parameters' in info:
                    parameters = str(info['parameters'])
                    if parameters:
                        lines = parameters.split('\n')
                        # æå–æ­£å‘æç¤ºè¯
                        for i, line in enumerate(lines):
                            if line.startswith('Negative prompt:'):
                                prompt_text = '\n'.join(lines[:i]).strip()
                                break
                        if not prompt_text and lines:
                            prompt_text = lines[0]
            
            return prompt_text, model_info, lora_info
            
        except Exception as e:
            print(f"âš ï¸  æå–å…ƒæ•°æ®å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return "", "", ""
    
    def load_image_with_metadata(self, image):
        """
        åŠ è½½å›¾ç‰‡å¹¶è¿”å›å›¾ç‰‡æ•°æ®ã€é®ç½©ã€å…ƒæ•°æ®ä¿¡æ¯
        
        Args:
            image: å›¾ç‰‡æ–‡ä»¶å
            
        Returns:
            tuple: (image_tensor, mask_tensor, prompt_text, model_info, lora_info)
                - image_tensor: å›¾åƒå¼ é‡ (B, H, W, C)
                - mask_tensor: é®ç½©å¼ é‡ (B, H, W)
                - prompt_text: æç¤ºè¯æ–‡æœ¬
                - model_info: æ¨¡å‹ä¿¡æ¯
                - lora_info: LoRAä¿¡æ¯
        """
        # è·å–å›¾ç‰‡è·¯å¾„
        image_path = folder_paths.get_annotated_filepath(image)
        
        # æå–å…ƒæ•°æ®
        prompt_text, model_info, lora_info = self.extract_metadata(image_path)
        
        # æ‰“å¼€å›¾ç‰‡
        img = node_helpers.pillow(Image.open, image_path)

        output_images = []
        output_masks = []
        w, h = None, None

        excluded_formats = ['MPO']

        # å¤„ç†å¤šå¸§å›¾ç‰‡ï¼ˆå¦‚GIFï¼‰
        for i in ImageSequence.Iterator(img):
            # å¤„ç†EXIFæ–¹å‘ä¿¡æ¯
            i = node_helpers.pillow(ImageOps.exif_transpose, i)

            # å¤„ç†ç‰¹æ®Šæ ¼å¼
            if i.mode == 'I':
                i = i.point(lambda i: i * (1 / 255))
            image_pil = i.convert("RGB")

            # æ£€æŸ¥å°ºå¯¸ä¸€è‡´æ€§
            if len(output_images) == 0:
                w = image_pil.size[0]
                h = image_pil.size[1]

            if image_pil.size[0] != w or image_pil.size[1] != h:
                continue

            # è½¬æ¢ä¸ºå¼ é‡ (H, W, C)
            image_np = np.array(image_pil).astype(np.float32) / 255.0
            image_tensor = torch.from_numpy(image_np)[None,]  # æ·»åŠ batchç»´åº¦ (1, H, W, C)
            
            # å¤„ç†Alphaé€šé“ï¼ˆé®ç½©ï¼‰
            if 'A' in i.getbands():
                # æœ‰Alphaé€šé“ï¼Œæå–é®ç½©
                mask_np = np.array(i.getchannel('A')).astype(np.float32) / 255.0
                mask = 1. - torch.from_numpy(mask_np)  # åè½¬é®ç½©
            elif i.mode == 'P' and 'transparency' in i.info:
                # è°ƒè‰²æ¿æ¨¡å¼ä¸”æœ‰é€æ˜åº¦ä¿¡æ¯
                mask_np = np.array(i.convert('RGBA').getchannel('A')).astype(np.float32) / 255.0
                mask = 1. - torch.from_numpy(mask_np)
            else:
                # æ²¡æœ‰Alphaé€šé“ï¼Œåˆ›å»ºå…¨é»‘é®ç½©
                mask = torch.zeros((h, w), dtype=torch.float32, device="cpu")
            
            output_images.append(image_tensor)
            output_masks.append(mask.unsqueeze(0))  # æ·»åŠ batchç»´åº¦ (1, H, W)

        # åˆå¹¶å¤šå¸§æˆ–è¿”å›å•å¸§
        if len(output_images) > 1 and img.format not in excluded_formats:
            output_image = torch.cat(output_images, dim=0)  # (B, H, W, C)
            output_mask = torch.cat(output_masks, dim=0)    # (B, H, W)
        else:
            output_image = output_images[0]  # (1, H, W, C)
            output_mask = output_masks[0]    # (1, H, W)

        # æ‰“å°è°ƒè¯•ä¿¡æ¯
        print(f"âœ… PDåŠ è½½å›¾ç‰‡(å«å…ƒæ•°æ®): {image}")
        print(f"   - å›¾åƒå¼ é‡å½¢çŠ¶: {output_image.shape}")
        print(f"   - é®ç½©å¼ é‡å½¢çŠ¶: {output_mask.shape}")
        print(f"   - æç¤ºè¯é•¿åº¦: {len(prompt_text)} å­—ç¬¦")
        print(f"   - æ¨¡å‹ä¿¡æ¯: {'å·²æ£€æµ‹åˆ°' if model_info else 'æœªæ£€æµ‹åˆ°'}")
        print(f"   - LoRAä¿¡æ¯: {'å·²æ£€æµ‹åˆ°' if lora_info else 'æœªæ£€æµ‹åˆ°'}")

        return (output_image, output_mask, prompt_text, model_info, lora_info)


# èŠ‚ç‚¹æ³¨å†Œ
NODE_CLASS_MAPPINGS = {
    "PD_LoadImageMetadata": PD_LoadImageMetadata
}

# èŠ‚ç‚¹æ˜¾ç¤ºåç§°æ˜ å°„
NODE_DISPLAY_NAME_MAPPINGS = {
    "PD_LoadImageMetadata": "PD Load Image (LoRA/JSON/Workflow)"
}

# å¯¼å‡ºèŠ‚ç‚¹ä¿¡æ¯ä¾›ComfyUIä½¿ç”¨
__all__ = ['NODE_CLASS_MAPPINGS', 'NODE_DISPLAY_NAME_MAPPINGS']

