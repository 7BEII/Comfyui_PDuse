import torch
import numpy as np
from PIL import Image

def tensor2pil(image):
    """å°†ComfyUIå›¾åƒå¼ é‡è½¬æ¢ä¸ºPILå›¾åƒ"""
    return Image.fromarray(np.clip(255. * image.cpu().numpy().squeeze(), 0, 255).astype(np.uint8))

def pil2tensor(image):
    """å°†PILå›¾åƒè½¬æ¢ä¸ºComfyUIå›¾åƒå¼ é‡"""
    return torch.from_numpy(np.array(image).astype(np.float32) / 255.0).unsqueeze(0)

class PD_RemoveBlackBackground:
    """
    å»é™¤å›¾åƒé»‘è‰²èƒŒæ™¯èŠ‚ç‚¹
    è¾“å…¥å›¾åƒï¼Œå»æ‰é»‘åº•ä¿ç•™ç™½è‰²åŒºåŸŸï¼Œè¾“å‡ºé€æ˜åº•PNG
    """
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image": ("IMAGE",),  # è¾“å…¥å›¾åƒå¼ é‡ [B, H, W, C]
                "threshold": ("FLOAT", {
                    "default": 0.9, 
                    "min": 0.0, 
                    "max": 1.0, 
                    "step": 0.01
                }),  # é»‘è‰²æ£€æµ‹é˜ˆå€¼ï¼Œä½äºæ­¤å€¼çš„åƒç´ è¢«è®¤ä¸ºæ˜¯é»‘è‰²
            },
            "optional": {
                "smooth_edges": ("BOOLEAN", {"default": True}),  # æ˜¯å¦å¹³æ»‘è¾¹ç¼˜
                "invert_mask": ("BOOLEAN", {"default": True}),  # æ˜¯å¦åè½¬æ©ç 
            }
        }

    RETURN_TYPES = ("IMAGE", "MASK")  # è¿”å›åŸå›¾åƒå’Œæ©ç 
    RETURN_NAMES = ("image", "mask")  # è¿”å›å€¼çš„åç§°
    FUNCTION = "remove_black_background"  # æŒ‡å®šæ‰§è¡Œçš„æ–¹æ³•åç§°
    CATEGORY = "PDuse/Image"  # å®šä¹‰èŠ‚ç‚¹çš„ç±»åˆ«

    def remove_black_background(self, image, threshold=0.9, smooth_edges=True, invert_mask=True):
        """
        å»é™¤å›¾åƒé»‘è‰²èƒŒæ™¯ï¼Œåˆ†åˆ«è¾“å‡ºæ©ç å’ŒåŸå›¾åƒ
        
        å‚æ•°ï¼š
            image (tensor): è¾“å…¥å›¾åƒå¼ é‡ [B, H, W, C]
            threshold (float): é»‘è‰²æ£€æµ‹é˜ˆå€¼ï¼Œ0.0-1.0ï¼Œä½äºæ­¤å€¼çš„åƒç´ è¢«è®¤ä¸ºæ˜¯é»‘è‰²
            smooth_edges (bool): æ˜¯å¦å¹³æ»‘è¾¹ç¼˜
            invert_mask (bool): æ˜¯å¦åè½¬æ©ç ï¼ŒTrueæ—¶é»‘è‰²åŒºåŸŸå˜é€æ˜ï¼ŒFalseæ—¶é»‘è‰²åŒºåŸŸä¿ç•™
            
        è¿”å›ï¼š
            image (tensor): åŸå§‹å›¾åƒå¼ é‡ [B, H, W, C]
            mask (tensor): é€æ˜åº¦æ©ç å¼ é‡ [B, H, W]ï¼Œæ ¹æ®invert_maskè®¾ç½®ç¡®å®šé»‘ç™½å«ä¹‰
        """
        # ç¡®ä¿è¾“å…¥å›¾åƒå¼ é‡çš„æ ¼å¼æ­£ç¡® [B, H, W, C]
        if image.dim() != 4:
            raise ValueError("è¾“å…¥å›¾åƒå¼ é‡å¿…é¡»æ˜¯ 4 ç»´çš„ [B, H, W, C]")
        
        batch_size, height, width, channels = image.shape
        
        # å¤„ç†æ¯å¼ å›¾åƒç”Ÿæˆæ©ç 
        result_masks = []
        
        for i in range(batch_size):
            # è·å–å•å¼ å›¾åƒ [H, W, C]
            single_image = image[i]
            
            # è®¡ç®—åƒç´ äº®åº¦ï¼ˆä½¿ç”¨åŠ æƒå¹³å‡ï¼šR*0.299 + G*0.587 + B*0.114ï¼‰
            rgb = single_image.cpu().numpy()
            brightness = np.dot(rgb, [0.299, 0.587, 0.114])
            
            # è°ƒè¯•ä¿¡æ¯ï¼šæ˜¾ç¤ºäº®åº¦ç»Ÿè®¡
            if i == 0:  # åªä¸ºç¬¬ä¸€å¼ å›¾åƒæ‰“å°è°ƒè¯•ä¿¡æ¯
                min_brightness = brightness.min()
                max_brightness = brightness.max()
                mean_brightness = brightness.mean()
                print(f"ğŸ” å›¾åƒäº®åº¦åˆ†æ:")
                print(f"   æœ€æš—åƒç´ : {min_brightness:.3f}")
                print(f"   æœ€äº®åƒç´ : {max_brightness:.3f}") 
                print(f"   å¹³å‡äº®åº¦: {mean_brightness:.3f}")
                print(f"   å½“å‰é˜ˆå€¼: {threshold:.3f}")
                print(f"   åè½¬æ©ç : {'å¼€å¯' if invert_mask else 'å…³é—­'}")
                print(f"   ä¿ç•™åŒºåŸŸ: {'äº®è‰²åŒºåŸŸ' if invert_mask else 'æš—è‰²åŒºåŸŸ'}")
            
            # åˆ›å»ºé»‘è‰²åƒç´ æ©ç ï¼šäº®åº¦ä½äºé˜ˆå€¼çš„åƒç´ è¢«è®¤ä¸ºæ˜¯é»‘è‰²èƒŒæ™¯
            black_mask = brightness < threshold
            
            # è°ƒè¯•ä¿¡æ¯ï¼šæ˜¾ç¤ºæ£€æµ‹ç»“æœ
            if i == 0:
                black_pixel_count = black_mask.sum()
                total_pixels = black_mask.size
                black_percentage = (black_pixel_count / total_pixels) * 100
                preserved_percentage = black_percentage if not invert_mask else (100 - black_percentage)
                print(f"   æ£€æµ‹åˆ°æš—è‰²åƒç´ : {black_pixel_count}/{total_pixels} ({black_percentage:.1f}%)")
                print(f"   æœ€ç»ˆä¿ç•™åŒºåŸŸ: {preserved_percentage:.1f}%")
            
            # å¦‚æœéœ€è¦å¹³æ»‘è¾¹ç¼˜ï¼Œå¯¹æ©ç è¿›è¡Œè½»å¾®æ¨¡ç³Šå¤„ç†
            if smooth_edges:
                try:
                    from scipy.ndimage import gaussian_filter
                    # å¯¹æ©ç è¿›è¡Œé«˜æ–¯æ¨¡ç³Šä»¥å¹³æ»‘è¾¹ç¼˜
                    smoothed_mask = gaussian_filter(black_mask.astype(np.float32), sigma=1.0)
                    # ä¿ç•™å¹³æ»‘è¿‡æ¸¡
                    black_mask = np.clip(smoothed_mask, 0, 1)
                except ImportError:
                    # å¦‚æœscipyä¸å¯ç”¨ï¼Œåˆ™ä½¿ç”¨ç¡¬è¾¹æ¨¡å¼
                    black_mask = black_mask.astype(np.float32)
            else:
                black_mask = black_mask.astype(np.float32)
            
            # åˆ›å»ºalphaæ©ç ï¼š1è¡¨ç¤ºä¿ç•™ï¼ˆä¸é€æ˜ï¼‰ï¼Œ0è¡¨ç¤ºé€æ˜
            if invert_mask:
                # åè½¬æ©ç ï¼šä¿ç•™éé»‘è‰²åŒºåŸŸï¼ˆäº®è‰²åŒºåŸŸï¼‰
                alpha_mask = 1.0 - black_mask
            else:
                # ç›´æ¥ä½¿ç”¨æ©ç ï¼šä¿ç•™é»‘è‰²åŒºåŸŸï¼ˆæš—è‰²åŒºåŸŸï¼‰
                alpha_mask = black_mask
            
            # è½¬æ¢ä¸ºå¼ é‡æ ¼å¼ [H, W]
            mask_tensor = torch.from_numpy(alpha_mask).float()
            result_masks.append(mask_tensor)
        
        # å †å æ‰€æœ‰æ©ç  [B, H, W]
        final_masks = torch.stack(result_masks, dim=0)
        
        return (image, final_masks)

# èŠ‚ç‚¹æ³¨å†Œ
NODE_CLASS_MAPPINGS = {
    "PD_RemoveBlackBackground": PD_RemoveBlackBackground
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "PD_RemoveBlackBackground": "PD:remove_background"
}
